{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38e5772e-6e8a-4221-a8c9-c56746f58b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tokenization\n",
      "\n",
      "['Once', 'upon', 'a', 'time', 'in', 'a', 'small', 'village', 'nestled', 'among', 'green', 'hills', ',', 'there', 'lived', 'a', 'young', 'shepherd', 'named', 'Peter', '.', 'He', 'spent', 'his', 'days', 'tending', 'to', 'his', 'flock', 'of', 'sheep', ',', 'wandering', 'through', 'meadows', 'and', 'singing', 'songs', '.']\n",
      "\n",
      "# POS Tagging\n",
      "\n",
      "[('Once', 'RB'), ('upon', 'IN'), ('a', 'DT'), ('time', 'NN'), ('in', 'IN'), ('a', 'DT'), ('small', 'JJ'), ('village', 'NN'), ('nestled', 'VBN'), ('among', 'IN'), ('green', 'JJ'), ('hills', 'NNS'), (',', ','), ('there', 'EX'), ('lived', 'VBD'), ('a', 'DT'), ('young', 'JJ'), ('shepherd', 'NN'), ('named', 'VBN'), ('Peter', 'NNP'), ('.', '.'), ('He', 'PRP'), ('spent', 'VBD'), ('his', 'PRP$'), ('days', 'NNS'), ('tending', 'VBG'), ('to', 'TO'), ('his', 'PRP$'), ('flock', 'NN'), ('of', 'IN'), ('sheep', 'NN'), (',', ','), ('wandering', 'VBG'), ('through', 'IN'), ('meadows', 'NNS'), ('and', 'CC'), ('singing', 'VBG'), ('songs', 'NNS'), ('.', '.')]\n",
      "\n",
      "# Stop Words Removal\n",
      "\n",
      "['upon', 'time', 'small', 'village', 'nestled', 'among', 'green', 'hills', ',', 'lived', 'young', 'shepherd', 'named', 'Peter', '.', 'spent', 'days', 'tending', 'flock', 'sheep', ',', 'wandering', 'meadows', 'singing', 'songs', '.']\n",
      "\n",
      "# Stemming\n",
      "\n",
      "['upon', 'time', 'small', 'villag', 'nestl', 'among', 'green', 'hill', ',', 'live', 'young', 'shepherd', 'name', 'peter', '.', 'spent', 'day', 'tend', 'flock', 'sheep', ',', 'wander', 'meadow', 'sing', 'song', '.']\n",
      "\n",
      "# Lemmatization \n",
      "\n",
      "['upon', 'time', 'small', 'village', 'nestled', 'among', 'green', 'hill', ',', 'lived', 'young', 'shepherd', 'named', 'Peter', '.', 'spent', 'day', 'tending', 'flock', 'sheep', ',', 'wandering', 'meadow', 'singing', 'song', '.']\n",
      "\n",
      "# TF-IDF Representation\n",
      "\n",
      "[[0.17149859 0.17149859 0.17149859 0.17149859 0.17149859 0.17149859\n",
      "  0.17149859 0.34299717 0.17149859 0.17149859 0.17149859 0.17149859\n",
      "  0.17149859 0.17149859 0.17149859 0.17149859 0.17149859 0.17149859\n",
      "  0.17149859 0.17149859 0.17149859 0.17149859 0.17149859 0.17149859\n",
      "  0.17149859 0.17149859 0.17149859 0.17149859 0.17149859 0.17149859\n",
      "  0.17149859]]\n",
      "\n",
      "# FEATURED NAMES \n",
      "\n",
      "['among' 'and' 'days' 'flock' 'green' 'he' 'hills' 'his' 'in' 'lived'\n",
      " 'meadows' 'named' 'nestled' 'of' 'once' 'peter' 'sheep' 'shepherd'\n",
      " 'singing' 'small' 'songs' 'spent' 'tending' 'there' 'through' 'time' 'to'\n",
      " 'upon' 'village' 'wandering' 'young']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#RUN BELOW COMMANDS ONLY ONCE AS WE NEED TO DOWNLOAD THESE LIBS. AFTER THAT COMMENT OR REMOVE THEM\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "#APART FROM THESE USE THE COMMAND \" pip install numpy scikit-learn \" in terminal to download numpy and scikit-learn\n",
    "\n",
    "document = \"Once upon a time in a small village nestled among green hills, there lived a young shepherd named Peter. He spent his days tending to his flock of sheep, wandering through meadows and singing songs.\"\n",
    "\n",
    "# TOKENIZATION\n",
    "print(\"# Tokenization\\n\")\n",
    "tokens = word_tokenize(document)\n",
    "print(tokens)\n",
    "\n",
    "# POS TAGGING\n",
    "print(\"\\n# POS Tagging\\n\")\n",
    "pos_tags = pos_tag(tokens)\n",
    "print(pos_tags)\n",
    "\n",
    "# STOP WORDS REMOVAL\n",
    "print(\"\\n# Stop Words Removal\\n\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "print(filtered_tokens)\n",
    "\n",
    "# STEMMING\n",
    "print(\"\\n# Stemming\\n\")\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "print(stemmed_tokens)\n",
    "\n",
    "# LEMMATIZATION\n",
    "print(\"\\n# Lemmatization \\n\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "print(lemmatized_tokens)\n",
    "\n",
    "# TF-IDF REPRESENTATION\n",
    "print(\"\\n# TF-IDF Representation\\n\")\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform([document])\n",
    "print(tfidf_matrix.toarray())\n",
    "print(\"\\n# FEATURED NAMES \\n\")\n",
    "print(tfidf_vectorizer.get_feature_names_out())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bbdf31-e68f-4534-a7f3-055bc259cd8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
